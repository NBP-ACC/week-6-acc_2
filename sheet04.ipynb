{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Osnabrück University - A\u0026C: Computational Cognition (Summer Term 2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Exercise Sheet 04: Analysis of behavioural data (part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This week\u0027s sheet should be solved and handed in at 14:00 at **Tuesday, May 14, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
        "\n",
        "In this exercise sheet we will have a closer look on the data of Seahaven using analysing techniques like ANOVA, linear regression models and t-tests. For the correct results we will provide you with the finalized data that you only have to read in. Note that especially the data for assignment 2 and 3 underwent some further preprocesing than what we did in the previous exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 0: Peer review for sheet 03 [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Open an issue in the repository of the groups you have to check. The title of the issue should be your group name (e.g. \"Group1). Comment on what was good and what was bad, the aesthetics and ease of reading the plots, what you would have done differently and how many points you would give them for their solutions.\n",
        "\n",
        "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
        "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
        "| check solutions of group: | 6, 2 | 10, 7  | 1, 6  | 8, 9 | 7, 1 | 9, 8 | 3, 10  | 5, 11  | 4, 3  | 11, 5 | 2, 4  |\n",
        "\n",
        "Please also evaluate nice coding style with up to two points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport ptitprince as pt\nimport seaborn as sns\nsns.set()\nfrom PIL import Image\nfrom scipy import stats\nfrom statsmodels.stats.anova import AnovaRM\nfrom statsmodels.stats.api import anova_lm\nfrom statsmodels.formula.api import ols\nfrom pathlib import Path"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 1: Linear Regression Model Based on Performance and Reaction Time [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Although the linear regression in the prior exercise sheet (assignment 2.a) does not suggest a relationship between RT and performance (accuracy) for the relative task, we still want to check how much of the performance is explained by the RT. To do so we fit a linear regression model by using the ```ols``` method in the ```statsmodels``` library for both of the time conditions (3sec and Infinite).\n",
        "\n",
        "- Read ```AllData.csv``` into the dataframe ```AllData``` and take only the data of the relative task. \n",
        "- Split the data of the relative task: Create ```SecData``` with the data of the 3sec-condition and ```InfData``` with the data of the Infinite-condition.\n",
        "- For each dataset (SecData, InfData) use the ```statsmodels```’ ```ols``` function to initialise a simple linear regression model. \u003cbr\u003e The ```ols``` function takes the following: **ols(\"y ~ X\", df)**, where X is the predictor variable (\"ReactionTime\"), y is the output variable (\"Performance\") and df is the dataframe of the used data.\n",
        "- Have a look on the R-squared values and interpret them.\n",
        "\n",
        "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html) and the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) to get a feeling how to use the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "------------ Time: 3sec -----------\n                            OLS Regression Results                            \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nDep. Variable:            Performance   R-squared:                       0.042\nModel:                            OLS   Adj. R-squared:                  0.032\nMethod:                 Least Squares   F-statistic:                     4.195\nDate:                Wed, 08 May 2019   Prob (F-statistic):             0.0433\nTime:                        13:30:11   Log-Likelihood:                 78.822\nNo. Observations:                  97   AIC:                            -153.6\nDf Residuals:                      95   BIC:                            -148.5\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n                   coef    std err          t      P\u003e|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept        0.4099      0.065      6.330      0.000       0.281       0.538\nReactionTime     0.0750      0.037      2.048      0.043       0.002       0.148\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nOmnibus:                        5.909   Durbin-Watson:                   2.092\nProb(Omnibus):                  0.052   Jarque-Bera (JB):                5.938\nSkew:                           0.604   Prob(JB):                       0.0513\nKurtosis:                       2.900   Cond. No.                         13.6\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n------------ Time: Infinite -----------\n                            OLS Regression Results                            \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nDep. Variable:            Performance   R-squared:                       0.118\nModel:                            OLS   Adj. R-squared:                  0.109\nMethod:                 Least Squares   F-statistic:                     12.72\nDate:                Wed, 08 May 2019   Prob (F-statistic):           0.000568\nTime:                        13:30:11   Log-Likelihood:                 86.422\nNo. Observations:                  97   AIC:                            -168.8\nDf Residuals:                      95   BIC:                            -163.7\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n                   coef    std err          t      P\u003e|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept        0.4826      0.025     19.197      0.000       0.433       0.533\nReactionTime     0.0228      0.006      3.567      0.001       0.010       0.035\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nOmnibus:                        3.385   Durbin-Watson:                   2.165\nProb(Omnibus):                  0.184   Jarque-Bera (JB):                2.764\nSkew:                           0.390   Prob(JB):                        0.251\nKurtosis:                       3.275   Cond. No.                         10.2\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# Load the data\nDATA_PATH \u003d Path(\"Data\", \"AllData.csv\")\nAllData \u003d pd.read_csv(DATA_PATH)\nAllData \u003d AllData[AllData[\"Task\"] \u003d\u003d \"Relative\"]\n\n# Create subsets and evaluate them for regression\nSecData \u003d AllData[AllData[\"Time\"] \u003d\u003d \"3sec\"]\nInfData \u003d AllData[AllData[\"Time\"] \u003d\u003d \"Infinite\"]\nfor data in (SecData, InfData):\n    print(\"------------ Time: {} -----------\".format(data[\"Time\"].iloc[0]))\n    linear_model \u003d ols(\u0027Performance ~ ReactionTime\u0027, data\u003ddata).fit()\n    print(linear_model.summary())"
    },
    {
      "cell_type": "markdown",
      "source": "In general, the R-squared values explain the influence of the predictor variable regarding the output variable. In this example, it therefore specifies how much of the performance is explainable by the observed reaction time. In the setup with a time limit, this amount of explainability is with 4.2% rather low. If the participants have no time constrains, already 11.8% of the performance are explainable by the reaction time.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "## Assignment 2: Testing Task Performance via ANOVA [5 pts]"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "For this assignment we will have a look on the whole data without caring about the different measurements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### a) Task Performance [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Refering to our plots of the prior exercise sheet (assignment 2.b), it is a good idea to have a closer look on the task performance (accuracy) to check if there are some **significant effects, i.e. p \u003c 0.05**. To do so we will first of all visualize the data with a raincloud-plot using ```ptitprince.RainCloud``` as a density estimate and then calculate the ANOVAs. Make sure to run ```pip install ptitprince``` in your activated acc environment beforehand.\n",
        "\n",
        "- Read ```MapPerformances.csv``` into the dataframe ```AllPerformances```.\n",
        "- Make a RainCloud-plot of the tasks (x-axis) and performance (y-axis) for both time conditions (3sec / Infinite). The y-axis should start at 0.25 and end at 0.75.\n",
        "- Have a look at ```help(pt.RainCloud)``` to get an overview of the different parameters that you can modify to create a nice raincloud-plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "help(pt.RainCloud)\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Using the data of ```AllPerformances``` we now want to calculate a **two-way ANOVA**. A two-way ANOVA is a statistical test used to determine the effect of two nominal predictor variables (\u003d independent variables) on a continuous outcome variable (\u003d dependent variable).\n",
        "\n",
        "H$_{01}$ \u003d The performance is the same for the different tasks. \u003cbr\u003e\n",
        "H$_{02}$ \u003d The performance is the same for the different time conditions. \u003cbr\u003e\n",
        "H$_{03}$ \u003d An interaction effect does not exist.\n",
        "\n",
        "- Given the null hypotheses above, what is the outcome variable and what are the predictor variables that you have to use for the two-way ANOVA?\n",
        "- Use ```statsmodels```’ ```ols``` function to create an ordinary least squares model as a precursor to the ANOVA. \u003cbr\u003e The ```ols``` function takes the following: **ols(\"y ~ C(X1) * C(X2)\", df)**, where X1 and X2 are the predictor variables, y is the output variable and df is the dataframe of the used data.\n",
        "- With the result of the ols calculate a **type 2** two-way ANOVA using ```statsmodels```’ ```anova_lm```.\n",
        "- Based on the ANOVA table explain which of the null hypotheses can be rejected. What does this outcome tell you?\n",
        "\n",
        "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html), the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) and the [anova_lm documentation](http://www.statsmodels.org/dev/anova.html) to get a feeling how to use these functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### b) Task Performance: 3sec Condition vs. Infinite Condition [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Let\u0027s take a closer look onto the single time conditions by calculating a **one-way ANOVA** for each time condition (3sec and Infinite). A one-way ANOVA is a statistical test used to determine the effect of one nominal predictor variable (\u003d independent variable) on a continuous outcome variable (\u003d dependent variable). \n",
        "\n",
        "H$_{01}$ \u003d The performance is the same for the different tasks. \u003cbr\u003e\n",
        "\n",
        "- Use the data of ```AllPerformances``` and split it: Create ```SecPerformances``` with the data of the 3sec-condition and ```InfPerformances``` with the data of the Infinite-condition.\n",
        "- Given the null hypothesis above, what is the outcome variable and what is the predictor variable that you have to use for the one-way ANOVAs?\n",
        "\n",
        "Do for each dataset (SecPerformances, InfPerformances):\n",
        "\n",
        "- Use ```statsmodels```’ ```ols``` function to create an ordinary least squares model as a precursor to the ANOVA. The ```ols``` function takes the formula \u003cbr\u003e The ```ols``` function takes the following: **ols(\"y ~ C(X)\", df)**, where X is the predictor variable, y is the output variable and df is the dataframe of the used data.\n",
        "- With the result of the ols calculate a **type 1** one-way ANOVA using ```statsmodels```’ ```anova_lm```.\n",
        "- Based on the ANOVA table explain if the null hypothesis can be rejected. What does this outcome tell you?\n",
        "\n",
        "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html) and the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) to get a feeling how to use this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "If there is a significant outcome for one of the datasets (SecPerformances or InfPerformances), make a post-hoc paired t-test using this dataset.\n",
        "\n",
        "- Extract the performances for each task (Absolute, Relative, Pointing).\n",
        "- Compare the performances of the different tasks pairwise using ```scipy.stats.ttest_rel```\n",
        "- Why do we need to do further post-hoc tests and what do they tell us?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "print(\"Absolute - Relative: \"+str(stats.ttest_rel())\n",
        "print(\"Absolute - Pointing: \"+str(stats.ttest_rel())\n",
        "print(\"Relative - Pointing: \"+str(stats.ttest_rel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 3: Testing Task Performance via Repeated Measures ANOVA [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Now we want to take a closer look on the task performance (accuracy) also taking the different measurements into account to check if there are some **significant effects, i.e. p \u003c 0.05**. For this purpose we have the averaged performances over 15 repeated measure subjects for three measurements. We will first of all visualize the averaged performances for each task for the three measurements with a catplot and then calculate a repeated measures ANOVA. \n",
        "\n",
        "- Read ```RepeatedPerformances.csv``` into the dataframe ```RepeatedPerformances```.\n",
        "- Make a catplot (kind\u003d\u0027barplot\u0027) of the conditions (x-axis) and the performance (y-axis). The y-axis should start at 0 and end at 0.75.\n",
        "- Please note that the conditions in the dataframe correspond to the given \"conditions\" list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "conditions \u003d [\"Absolute - 3sec \",\"Absolute - Infinite\",\"Relative - 3sec \",\"Relative - Infinite\",\"Pointing 3sec\",\"Pointing - Infinite\"]\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# create a usable dataframe for the following analysis\n",
        "repgroup \u003d RepeatedPerformances.groupby([\u0027Measurement\u0027,\u0027Subject\u0027,\u0027Condition\u0027], as_index\u003dFalse)[\u0027Performance\u0027].mean()\n",
        "\n",
        "RepeatedDf \u003d pd.DataFrame(columns\u003d{\u0027Measurement\u0027,\u0027Subject\u0027,\u0027Task\u0027,\u0027Time\u0027,\u0027Performance\u0027})\n",
        "tasks \u003d [\u0027Absolute\u0027,\u0027Absolute\u0027,\u0027Relative\u0027,\u0027Relative\u0027,\u0027Pointing\u0027,\u0027Pointing\u0027]\n",
        "times \u003d [\u00273sec\u0027,\u0027Infinite\u0027,\u00273sec\u0027,\u0027Infinite\u0027,\u00273sec\u0027,\u0027Infinite\u0027]\n",
        "for i in range(270):\n",
        "    RepeatedDf \u003d RepeatedDf.append({\u0027Subject\u0027:repgroup[\u0027Subject\u0027][i],\u0027Measurement\u0027:repgroup[\u0027Measurement\u0027][i],\u0027Task\u0027:tasks[repgroup[\u0027Condition\u0027][i]],\u0027Time\u0027:times[repgroup[\u0027Condition\u0027][i]],\u0027Performance\u0027:repgroup[\u0027Performance\u0027][i]},ignore_index\u003dTrue)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Using the data of ```RepeatedDf``` we want to calculate a **(three-way) repeated measures ANOVA**. A (three-way) repeated measures ANOVA in general is a statistical test used to determine the effect of three nominal predictor variables (\u003d within-subject factors) on a continuous outcome variable (\u003d dependent variable). \n",
        "\n",
        "\n",
        "\n",
        "- What is the dependent variable and what are the within-subject factors that you have to use for the repeated measures ANOVA?\n",
        "- Formulate the null hypotheses that the repeated measures ANOVA has to test.\n",
        "- Calculate a repeated measures ANOVA using ```statsmodels```\u0027 ```AnovaRM```. \n",
        "- Based on the ANOVA table explain which of the null hypotheses can be rejected. What does this outcome tell you?\n",
        "\n",
        "Take a look at the [ANOVARM documentation](http://www.statsmodels.org/dev/generated/statsmodels.stats.anova.AnovaRM.html#statsmodels.stats.anova.AnovaRM) to get a feeling how to use this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 4: Spatial coverage of Seahaven [Bonus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "To get a better feeling of the spatial coverage of Seahaven, we can create an overview of the houses that the subjects have seen. With a colormap it is easy to display the spatial coverage in an intuitive way.\n",
        "\n",
        "- Open the image ```map5.png``` as ```SeahavenMap``` and read ```Clicks.csv``` into a dataframe ```NumClicks```.\n",
        "- Draw a solid circle for each house. Use the x- and y-coordinates of ```NumClicks``` for the positioning of the circles.\n",
        "- The column \"clicks\" from ```NumClicks``` displays how many subjects had visited the respective house. Use these click-values to calculate each circle\u0027s colour:\n",
        "\n",
        "$CircleColor \u003d cmap((click[i]-min(clicks))/(max(clicks)-min(clicks)))$\n",
        "\n",
        "$clicks$: list/array of all click-values from the dataframe ```NumClicks``` \u003cbr\u003e\n",
        "$click[i]$: a certain click-value from the dataframe ```NumClicks``` at position $i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# open the files and extract the necessary data\n",
        "# TODO\n",
        "\n",
        "\n",
        "# set everything up to display the Seahaven Map\n",
        "fig \u003d plt.figure(figsize\u003d(15,15))\n",
        "SeahavenMap \u003d SeahavenMap.resize((450,500))\n",
        "ax \u003d plt.subplot2grid((10, 10), (0, 0), colspan\u003d9,rowspan\u003d10)\n",
        "plt.imshow(SeahavenMap, aspect \u003d \u0027equal\u0027)\n",
        "\n",
        "# choose a colormap for the circles that display the houses\n",
        "cmap \u003d plt.cm.get_cmap(\u0027Reds\u0027)\n",
        "\n",
        "# draw the circles and give them the right color (using the given colormap)\n",
        "# TODO\n",
        "\n",
        "\n",
        "# set everything up to display the Colormap / legend for the circle\u0027s colors\n",
        "a\u003dnp.outer(np.arange(0,1,0.01),np.ones(3))\n",
        "ax2 \u003d plt.subplot2grid((10, 10), (0, 9),rowspan\u003d10)\n",
        "plt.imshow(a,aspect\u003d\u0027auto\u0027,cmap\u003d\u0027Reds\u0027,origin\u003d\"lower\")\n",
        "ax2.get_xaxis().set_ticks([])\n",
        "ax2.get_yaxis().set_ticks(np.linspace(0,99,10))\n",
        "ax2.get_yaxis().set_ticklabels(np.linspace((min(clicks)/64)*100,(max(clicks)/64)*100,10,dtype\u003dint))\n",
        "ax2.yaxis.tick_right()\n",
        "ax2.set_ylabel(\"Percentage of Subjects That Have Seen This House\",rotation\u003d270, fontsize\u003d15, labelpad\u003d20)\n",
        "ax2.yaxis.set_label_position(\"right\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-70970a36",
      "language": "python",
      "display_name": "PyCharm (week-4-acc_2)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}